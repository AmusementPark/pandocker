# 定义a1的组件
a1.sources = r1
a1.channels = c1
a1.sinks = k1


# 配置source属性和值
a1.sources.r1.type = avro
a1.sources.r1.bind = flume-tier2-1
a1.sources.r1.port = 2018
a1.sources.r1.threads = 18
a1.sources.r1.channels = c1

# 添加 interceptor，配合 kafka sink，将event写入相应的分区
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = regex_extractor
# 提取处 userId
a1.sources.r1.interceptors.i1.regex = "userId":\\s+(\\d+)
# 将提取出的 userId 放入 event header 中
a1.sources.r1.interceptors.i1.serializers = s1
a1.sources.r1.interceptors.i1.serializers.s1.type = default
a1.sources.r1.interceptors.i1.serializers.s1.name = userId


# 配置sink属性和值
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.bootstrap.servers = broker1:9092, broker2:9092, broker2:9092
a1.sinks.k1.kafka.topic = user_behavior
a1.sinks.k1.flumeBatchSize = 1000
# 1 (wait for leader only), -1 (wait for all replicas, this can avoid data loss in some cases of leader failure)
a1.sinks.k1.kafka.producer.acks = 1
# a1.sinks.kafka.producer.* = "value"
# event header 中只有一个属性 userId
# a1.sinks.k1.partitionIdHeader = userId
a1.sinks.k1.channels = c1


# 配置 channels 信息
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 1000
# 添加或者移除events的超时时间 秒
a1.channels.c1.keep-alive = 10

